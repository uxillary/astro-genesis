{
  "id": "exp_022",
  "title": "FAIRness and Usability for Open-access Omics Data Systems",
  "authors": [
    "Daniel C Berrios",
    "Afshin Beheshti",
    "Sylvain V Costes"
  ],
  "year": 2015,
  "organism": "Mus musculus",
  "platform": "ISS",
  "keywords": [
    "systems",
    "metadata",
    "are",
    "omics",
    "glds",
    "metric",
    "system",
    "not"
  ],
  "sections": {
    "abstract": "Omics data sharing is crucial to the biological research community, and the last decade or two has seen a huge rise in collaborative analysis systems, databases, and knowledge bases for omics and other systems biology data. We assessed the “FAIRness” of NASA’s GeneLab Data Systems (GLDS) along with four similar kinds of systems in the research omics data domain, using 14 FAIRness metrics. The range of overall FAIRness scores was 6-12 (out of 14), average 10.1, and standard deviation 2.4. The range of Pass ratings for the metrics was 29-79%, Partial Pass 0-21%, and Fail 7-50%. The systems we evaluated performed the best in the areas of data findability and accessibility, and worst in the area of data interoperability. Reusability of metadata, in particular, was frequently not well supported. We relate our experiences implementing semantic integration of omics data from some of the assessed systems for federated querying and retrieval functions, given their shortcomings in data interoperability. Finally, we propose two new principles that Big Data system developers, in particular, should consider for maximizing data accessibility.",
    "methods": "NASA GeneLab GeneLab ( http://genelab. nasa. gov ) is a NASA initiative designed to accelerate “open science” biomedical research in support of the human exploration of space and the improvement of life on earth. 20 GeneLab data have been used to research impacts of space on mice, humans, and plants. Phase I of GeneLab Data Systems (GLDS) project implemented an “omics” (genomics, transcriptomics proteomics, and metabolomics) data repository for biomedical research data conducted in or relevant to space environments ( Figure 1 ). This initial phase developed processes and systems for data submission, curation, indexing, search, and retrieval. In Phase II GeneLab implemented federated search and retrieval capabilities for data hosted by GeneLab and three other open-access, omics data systems, in order to facilitate data integration and biological meta-investigation ( Figure 1 a). 21 (Note that these targets for search federation were selected independently and using different criteria than the data systems evaluated in this paper). Such meta-investigations are key to corroborating findings from different studies and/or kinds of bioassay data, and translating them into systems biology knowledge and, eventually, therapeutics 22 . In Phase III, GeneLab has begun to deploy an omics data analysis platform as part of the GLDS. Using this platform, investigators can design, execute and share in silico experimentation of omics data sets ( Figures 1 b and 1 c). At the end of Phase III, users with results of these kinds of experiments will be able to store them directly into the GLDS repository, linked to originating data and to the analysis workflows that generated them. Figure 1. Open in a new tab The GeneLab Data Systems (GLDS). (a) The GeneLab Data Repository. The federated search interface shown includes not only search of GLDS repository data, but of the extramural data sources Gene Expression Omnibus (“GEO” 4 ), PRoteomics IDEntifications repository (“EBI PRIDE” 5 ), and the Metagenomics Analysis server (“ANL MG-RAST” 6 ). (b) The GLDS Workspace. (c) GLDS Tools for omics data analysis (part of a Galaxy server 1 ). Even though the inception of the GLDS predated publication of the FAIR principles, many of the concepts behind the principles were discussed extensively prior to its design. These discussions included substantial input from the National Academies of Sciences and a steering committee of outside experts in omics biological data, and had significant impacts on selection of technological approaches and system architectures, required resources for development and operations, and policies developed for operating the GLDS. In the absence of best practices from the community in certain areas of design and policy ( Figure 2 ), we wondered how we might assess the impact on FAIRness of the design and policy choices we faced, and how the GLDS would compare in FAIRness to other open-access, Big Data systems. Figure 2. Open in a new tab The FAIR principles 18 , and areas of design and operations of FAIR data systems (white boxes) for which best practices have yet to be defined. FAIRness of Omics Data The FAIR principles were designed to guide the management of data so that it is maximally findable, accessible, interoperable, and reusable. They are not precise prescriptions for FAIR system design specifications; rather they are aspirational guidelines with some references to exemplar standards and technologies. Among the findability principles are requirements that data be assigned a persistent, global unique identifier (GUID), be described by rich metadata, and be indexed by a system for retrieving the data. Accessibility requires the use of standardized, open (available for implementation to all) communications protocols for retrieval of data by GUID. Interoperability is supported through the use of machine-actionable metadata and data. Reusability requ i res systems to be compliant in the management of their data objects with the first three principles, specifically so that data and metadata can be linked and integrated across FAIR systems. Each of the authors assessed compliance of four open-access, omics data systems and the GLDS for FAIRness using the current working draft of the FAIRness metrics developed by the GO FAIR Metrics group 23 (Table 1). The four systems selected were the Gene Expression Omnibus (GEO), the European Nucleotide Archive (ENA), the Metagenomics Analysis Server (MG-RAST), and Metabolights. We chose the systems for their similarity to the GLDS; all are open-access, government-operated or government-funded, research lab-developed omics data systems. As the FAIR principles themselves are only aspirational, the assessment of the systems can only be at most semi-quantitative, and they would likely be affected by further clarifications or details in the principles and/or metrics which are almost certain to come. We rated systems with Pass when we had no evidence of any failure of a test by the metric. Systems were rated as Partial Pass, if the metric had multiple steps or components, and the system passed some, but not all; or if we had evidence that some data inputs for the metric yielded a pass, while others did not. We chose Fail only if we could find no evidence the system was compliant with any part of the metric, for any inputs we tried. Individually-assessed ratings were then combined into the consensus ratings shown in Table 1 through dialogue among the raters. Finally, we developed an overall FAIRness Score by assigning a score to each rating of 1 for each Pass, 0.5 for each Partial Pass, and 0 for each Fail and totaling these score for each system. Table 1. The FAIR principles, corresponding draft FAIRness metrics, and semi-quantitative FAIRness ratings for select omics data systems. Metrics were those developed by the GO FAIR Metrics 23 group. Open in a new tab Summary of FAIRness Assessments There is quite some variability in FAIRness among the omics data systems we assessed using the 14 metrics. The range of Pass ratings was 29-79% of metrics, Partial Pass 0-21%, and Fail 7-50%. The range of overall FAIRness scores was 6-12, with average of 10.1 and standard deviation, 2.4. All the systems were rated best in the areas of data accessibility and reusability, slightly worse in data findability, and far worse in data interoperability. Findability The first findability principle, F1 ( Table 1 ), states that systems should identify data using globally unique and persistent identifiers; the FM-F1A metric focuses on identifier uniqueness, and FM-F1B on identifier persistence. The objective is to make data findable, but the implementation of F1 also supports data accessibility (FAIR principle A1). The qualifier “global” should be interpreted as global within the domain of conceivable use of the data. Thus, it is not sufficient to use locally (system-specific) controlled processes to manage data identifiers 24 , as this approach can never absolutely guarantee against overlap with other systems’ local identifier schemes. In addition, F1 specifies the persistence of issued identifiers; identification systems that employ Uniform Resource Locators (which rely on alterable domain name resolution) cannot guarantee persistence of identifiers. Among the schemes for providing data identifiers, the most reliable over time are likely to be those that use third-party resolution (versus those that rely on in-house redirection). Third-party resolution identifiers include Digital Object Identifiers (DOIs) and those provided by identifers.org, among others 25 . All but one of the systems we assessed passed the metric for F1 metric by employing persistent, globally unique identifiers with third party resolution. (MG-RAST only offers such identifiers as an option during data submission, and so was assessed as Partial Pass.) In the biomedical research and clinical practice realms, publishers have now widely selected the DOI scheme for identification and citation of literature; more than 80% of 2015 articles indexed by PubMed have assigned DOIs 26 . As a consequence, the biomedical community is already (and continues to become more and more) familiar with using these identifiers to retrieve and cite literature. Yet to date only a few omics data repositories have similarly implemented DOIs for data publications. Consequently, actual findability and accessibility of data in these repositories is less than optimal, even though they are technically in compliance with F1, and will continue to be so, unless and until the biomedical community is trained on how to use other identifying schemes for citing data. Furthermore, metadata from these repositories are not currently indexed in DOI meta-indexes (such as the one produced by DataCite 27 ). In order to be compliant with F1 and A1, the GLDS is implementing methods to issue DOIs for all data publications. Additionally, curated metadata records of the publications are transmitted to DataCite 27 for meta-indexing, increasing the chances for reuse of GLDS-hosted data. FAIR data also need to be described “with rich metadata” in order to be findable. The draft metric to assess F2 compliance merely requires a metadata description document that specifies a format for machine-readable metadata. The definition of the term “machine-readable” varies somewhat, but it is generally agreed that it cannot be natural language. (Although F2 refers to reusability principles requiring data “have a plurality of accurate and relevant attributes” (R1), the metric for F2 does not attempt to assess compliance with principle R1 [perhaps it should]). All the systems we assessed passed this metric. Furthermore, all systems passed F3, requiring association of metadata with data it describes. It should be noted that FM-F3 refers only to IRIs and not broadly to any other kinds of acceptable data identifiers; we assume that ultimately FM-F3 will be broadened to allow other kinds of F1-compliant data identifiers. Also, it is difficult to determine if any of the systems truly support IRIs, given that none of them currently appear to use non-ASCII character encodings in their data identifying schemes. The FAIRness metric FM-F4 is rather ill-defined currently. It requires submission of an identifier of FAIR data and its metadata to search engines (which precisely, it does not yet specify, but some common search engines are mentioned as examples in the comments for the metric). A Pass should be given if the returned search results include links to the published data (again, it does not yet specify where in the returned results, although among both the top 10 and top 40 are mentioned in metric comments). Some of the systems we assessed failed this metric, and it seems their data records are likely not indexed by at least some search engines. For example, search of the MG-RAST data record identified by “ http://metagenomics.anl.gov/linkin.cgi?metagenome=mgm4447971.3 ” or any of its tabular metadata yielded no search results referring to the repository using Google. More of the systems would fail this metric if it required data to be submitted specifically to DOI-based search systems (such as DataCite). Accessibility All of the systems for which we assessed compliance with FAIR principle A1.1 passed; all use open source communication protocols to access data, which are retrieved by their identifiers. FAIR Principle A1.2 stipulates that any protocol used to retrieve data “allows for an authentication and authorization procedure, where necessary.” All the systems we assessed describe which functions of the system require credentials, and how to obtain the credentials. It should be noted that A1.2 can be applied to the design of all types of systems, from those with highly restricted access controls, to the kinds of “open access” systems we assessed, that typically require minimal authentication and grant the widest possible access to all users. Furthermore, the data in question could be any kind of data, including raw instrument output, shared data analysis workflows or data products, or scientifically-relevant user comments and opinions. Even for open access systems, some systems functions such as user-workspace file management, user commenting and messaging, and user attribution of data always require authentication, because these functions must necessarily leverage user-specific information. A specific challenge that GeneLab faced when implementing A1.2 for the GLDS was a diversity of credentialing services available to the system’s target users, with no single service common to all users. Furthermore, the goal of GeneLab is to maximize access to GLDS data across all kinds of users, but within the bounds of authentication and credentialing policies of NASA - another challenge. Aside from policy restrictions, the development of any new credentialing and authentication functions or services can require considerable resources. A solution for organizations that are seeking to develop open-access systems is to consider investing in development of an organization-wide integrated credentialing and authentication architecture (ICAA, Figure 3 ), and policies for allowing users to leverage extramural credentials, with appropriate access limitations. ICAAs and attendant policies can provide flexibility to develop and/or deploy data systems with available resources that can meet policy requirements of the organization that support extramural user access. It should be noted that using an ICAA to leverage credentialing systems developed independently from the system requires 1) technical compatibility between the authentication services of credentialing providers and the ICAA; and 2) compatibility of the credentialing policies of credentialing organizations and those of the organization developing the data system. Technical compatibility is facilitated through the use of authentication protocols and standards. Organizational credentialing policy incompatibility is more problematic to resolve. For example, it may be that the organization deploying the data system requires credentials be updated at an interval that is different from that required by one or more extramural credential provider. If these differences cannot be resolved, the only option may be to limit access for some extramural users data system functions requiring authentication. Figure 3. Open in a new tab Use of an Integrated Credentialing and Authentication Architecture (ICAA) to comply with FAIR principle A1.2. The ICAA provides services and policies that use information from intra- and extramural credentialing services to authenticate users of a data system. NASA is developing an ICAA and adopting policies that permit certain intramural data systems to leverage it for user credentials and authentication. These policies stipulates that users within the organization must use the organization’s own credentialing services, while extramural users may authenticate using one from a defined set of externally-managed credentialing systems (currently including authentication by selected “social media” systems, such as Google.com credentials). At NASA (and at most U.S. federal agencies), intramural credentialing is quite a long process involving corroboration of much identifying information. The use of the ICAA, users without NASA credentials can specify a minimum of information (e.g., only a verifiable email address), which they can provide easily through a web browser, and gain almost immediate access to the GLDS. Through use of the ICAA, the GLDS is able to recognize a lower level of confidence when authenticating extramural users, and implement appropriate access controls to some functions for these users (e.g., they may not join system administrator groups). It seems reasonable to suggest that an additional principle be considered when designing FAIR data systems that have at least some functions requiring authentication or authorization (A1.2.1 in Table 2 ). This principle, would stipulate that an integrated credentialing architecture, like that shown in Figure 3 be leveraged, in order to offer access to data to the widest number of users possible, when and where data policies permit such access. Table 2. Additional principles for optimizing data accessibility Open in a new tab Most of the systems we assessed for FAIR compliance to A2 have some policy to retain at least some metadata when data are removed from the system. It is frequently unclear, however, which metadata were to be retained when data records are removed from the system. Data systems should ensure that policies for retaining metadata are clearly stated, including which metadata and for what period of time. Another factor that specifically affects accessibility to Big Data is data transport. Data to be used as inputs in Big Data systems, but which are not located in the same environment as executable code of the system, commonly must first be transported (duplicated or moved) to the environment first. This environment typically is a user-specific workspace. The transport process for Big Data can require minutes, hours or even days in some Big Data systems, and represents a significant barrier to efficient access. Designers of Big Data would benefit from a principle that stipulates the collocation within Big Data systems of data and executable code (A3 in Table 2 ). Interoperability I1 stipulates the “use a formal, accessible, etc. language for knowledge representation. The draft metric for this principle requires that the language for data or metadata be available by URL, and have a BNF representation. The comments on the metric suggest additional required language qualities, including that the language must have semantics (“[‘vanilla’] xml and json ..should fail”). While current knowledge representation languages such as RDF and OWL 28 are available to generate metadata specifications with inherent semantics, tools that leverage such languages require some sophistication in their use. All the repositories we assessed have metadata specifications that do not have inherent semantics, and thus would not yield a Pass for this metric. Metabolights and the GLDS both use the ISATab metadata specification, which can be converted to RDF, and so were rated with Partial Pass. The metric for principle I2 has a related requirement: that data systems use open, community-developed vocabularies for data and metadata, and that such vocabularies be more than simple keywords (i.e., include semantics in some form). As the ISATab specification supported ontological lookup from such vocabularies, we again only rated Metabolights and the GLDS with Partial Pass, and the rest of the systems as FAIL. In addition to lack of experience with knowledge representation technologies like RDF and OWL, another likely reason for lack of compliance of the systems with I1 and I2 is a general lack of available semantic resources developed by the community to generate metadata specifications and vocabularies, particularly in more recent domains like genomics, proteomics and metabolomics. We have ourselves sought such resources for use in the GLDS development, where we are seeking to provide users with omics data analysis capabilities, an omics “workbench” consisting of user-specific workspaces and data access controls, together with access to a suite of omics analysis tools (see Figure 1 b and Figure 1 c). Users of these tools will create data processing (analysis) workflows to transform input data into “higher-order” data products, which they will likely want to share with others and/or associate with the workflows and data inputs. One of the challenges we have observed for making these kinds of processed information FAIR include a lack of semantic resources for creating metadata specifications for such processed data and the processing workflows that generate them. While schemas like the Common Workflow Language 29 (CWL) specification provide a method to represent and reproduce the mechanics of data processing, they lack domain-specific semantics regarding the nature of these data transformations (e.g., what are the goals of the transformation from a biological perspective? What are the biological data concepts produced in output files? how do these relate to input data elements? etc.). Without these descriptors, systems may not adequately index these processed data and workflows for discovery and retrieval. While sophisticated users (e.g., trained bioinformaticians) who do encounter processed data and workflows may be able to understand and reuse them, others without domain-specific experience and knowledge of omics data processing may not. A challenge for the GLDS will be to help spur the creation of community resources so that it can implement rich metadata for processed omics data and workflows in a timely fashion. The objective of the metric for principle I3 is to measure how much data in one system are linked semantically to data in other systems. It is not surprising that none of the data sources link data “out” to data in external systems in semantically qualified ways; this is a challenging objective for any data system. (We ignored links to records that were merely duplicated between systems) Manual linking of data requires subject matter expertise and can be time-consuming for systems with many data records. Automated linking requires that source and linked data both be characterized semantically so that links may be inferred. As mentioned above, semantic resources for characterizing omics data are by and large still forthcoming. Reusability R1 is referred to by the findability FAIR principle F2 (see above); at this time there is no metric specifically for R1. R1.1 requires data systems to provide licenses for data usage (and is curiously intended to facilitate “legal interoperability” rather than reusability 30 . All the data repositories we assessed are governmental entities, and as such, licensing is traditionally prohibited. R1.2 and R1.3 require that data are published together with provenance metadata, and that data and metadata conform to community-derived standards, respectively. Such standards include taxonomies, ontologies and other vocabularies for metadata, and data and file formats. The metric for R1.2 involves the demonstration that a system can provide FAIR-compliant citational and contextual provenance metadata. While all the repositories provide such metadata, some do not use FAIR-compliant schemes for these metadata. Similarly, most of the repositories assess and validate submitted data files (but few validate metadata, as discussed above) against FAIR-schemes and formats.",
    "results": "",
    "conclusion": "There is quite some variability in FAIRness among the omics data systems we assessed using the 14 metrics. The range of Pass ratings was 29-79% of metrics, Partial Pass 0-21%, and Fail 7-50%. The range of overall FAIRness scores was 6-12, with average of 10.1 and standard deviation, 2.4. All the systems were rated best in the areas of data accessibility and reusability, slightly worse in data findability, and far worse in data interoperability."
  },
  "links": {
    "pmc_html": "https://pmc.ncbi.nlm.nih.gov/articles/PMC6371294/",
    "pmc_pdf": "https://pmc.ncbi.nlm.nih.gov/articles/PMC6371294/pdf/2975810.pdf"
  },
  "ai_summary": "This study evaluates the \"FAIRness\" of NASA's GeneLab Data Systems (GLDS) and four comparable omics data systems, focusing on their ability to share and integrate biological data effectively. Using 14 FAIRness metrics, the researchers found that the systems scored between 6 and 12, with an average score of 10.1, indicating moderate performance in data sharing. Notably, while data findability and accessibility were rated relatively high, interoperability was a significant weakness, with many systems failing to support the reusability of metadata. These findings highlight critical gaps in data integration capabilities, which are essential for advancing research in space biosciences. The study emphasizes the need for improved interoperability and proposes two new principles for developers to enhance data accessibility. By addressing these issues, the research aims to foster collaborative investigations that can better support biomedical research relevant to both space exploration and terrestrial applications.",
  "access": [
    "PEER-REVIEWED",
    "ISS",
    "SPACE BOTANY"
  ],
  "citations_by_year": [],
  "confidence": 0.71,
  "entities": [
    "systems",
    "metadata",
    "are",
    "omics",
    "glds"
  ]
}